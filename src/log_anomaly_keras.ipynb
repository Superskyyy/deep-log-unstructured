{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "orig_nbformat": 3,
    "colab": {
      "name": "log_anomaly_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "e9-rLqiqeoQJ"
      ],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b6ec10da5f54c80826b82ad0cc81ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2948f509273b4addb1ea823f70b67987",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a641398ed6e8433a9b00178f64d237ae",
              "IPY_MODEL_b72d7f8ee9454861934689700a8ac40c",
              "IPY_MODEL_3bb6965c6f304014bcaed61a3ee9eaac"
            ]
          }
        },
        "2948f509273b4addb1ea823f70b67987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a641398ed6e8433a9b00178f64d237ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f8d5d7b61b0f4188a955a1eb1bbcaa81",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e48ada6251dd47e0919c383155d63db8"
          }
        },
        "b72d7f8ee9454861934689700a8ac40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dc90096f9f304517b4e071b8328bb8a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44a70aa6102a4d5fa3dc75422a0f3bb5"
          }
        },
        "3bb6965c6f304014bcaed61a3ee9eaac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6aa2cba887cb4b8ab83aa9bd1e1caa5d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11000000/? [00:50&lt;00:00, 221183.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef5f69e4d2d34af684d3704a85162c71"
          }
        },
        "f8d5d7b61b0f4188a955a1eb1bbcaa81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e48ada6251dd47e0919c383155d63db8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc90096f9f304517b4e071b8328bb8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44a70aa6102a4d5fa3dc75422a0f3bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6aa2cba887cb4b8ab83aa9bd1e1caa5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef5f69e4d2d34af684d3704a85162c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77b5ee5fe97949dc91f53608b9590723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71f60ab4ae3b415b9ec647f89f107714",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9406c0652ca14151aecea74e567aa54e",
              "IPY_MODEL_b72d182d2c4142efa918714560752704",
              "IPY_MODEL_db1afe03fdca43ae917c3f8e6e199ac2"
            ]
          }
        },
        "71f60ab4ae3b415b9ec647f89f107714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9406c0652ca14151aecea74e567aa54e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_878363b53b3d4db89ada90fede5e5faf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84a7b1d8847045268430d2c78e083c6c"
          }
        },
        "b72d182d2c4142efa918714560752704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_be22fdc8455a44b4b90d5e21ab8a9bcc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aed225dd8c714053bdbb23746ce5d5b0"
          }
        },
        "db1afe03fdca43ae917c3f8e6e199ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df5c4a1beca749c595f183bc98846f59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5000001/? [00:16&lt;00:00, 328016.07it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2909aaf54de94629a4f3a375759162cd"
          }
        },
        "878363b53b3d4db89ada90fede5e5faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84a7b1d8847045268430d2c78e083c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be22fdc8455a44b4b90d5e21ab8a9bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aed225dd8c714053bdbb23746ce5d5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df5c4a1beca749c595f183bc98846f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2909aaf54de94629a4f3a375759162cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6d18ea014e34037bcb9c3214d2429c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c2400531d05547a189b1cf38766a86de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ebd2bf11397649489096663baac50465",
              "IPY_MODEL_e75c231a996047df816fec48d31a5609",
              "IPY_MODEL_10ec5681ea944f888a0b6049bab78389"
            ]
          }
        },
        "c2400531d05547a189b1cf38766a86de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebd2bf11397649489096663baac50465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e452b68e45544615ba6d507fd9a63fb3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43a1dd4548804615998a2292b26eba25"
          }
        },
        "e75c231a996047df816fec48d31a5609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_014ca57216f544c59d9ef31b52649f00",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25886b0b95974750a40084141f355ea4"
          }
        },
        "10ec5681ea944f888a0b6049bab78389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f6513c9a0e504a8e9a76de2f1f41869b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4747963/? [00:57&lt;00:00, 26406.24it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1170f4a9fb094400ab53ba4e044529aa"
          }
        },
        "e452b68e45544615ba6d507fd9a63fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43a1dd4548804615998a2292b26eba25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "014ca57216f544c59d9ef31b52649f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25886b0b95974750a40084141f355ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6513c9a0e504a8e9a76de2f1f41869b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1170f4a9fb094400ab53ba4e044529aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc343d73dfa14543a81d2bd01523eca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_003189f2331f4256bbb4beb58a4aa1ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91350cefadca44de9307f88c6176451b",
              "IPY_MODEL_51e48d5d6a56482e9bb020039b4cf40c",
              "IPY_MODEL_884c79a828ac4c178801cd9a677c9acd"
            ]
          }
        },
        "003189f2331f4256bbb4beb58a4aa1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91350cefadca44de9307f88c6176451b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_302e3cb8fcf442c48df873e077309616",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52d16e27a3294efaa9c314211387bb42"
          }
        },
        "51e48d5d6a56482e9bb020039b4cf40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_72dd71470a4c48b7abd8811f106df893",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09d25232d79a46fb823149a37f112a04"
          }
        },
        "884c79a828ac4c178801cd9a677c9acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a089e0e48c24d55b9076f7696e4c215",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100000/? [00:03&lt;00:00, 77411.55it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a891bf7e0a4a43408754930734041adc"
          }
        },
        "302e3cb8fcf442c48df873e077309616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52d16e27a3294efaa9c314211387bb42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72dd71470a4c48b7abd8811f106df893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09d25232d79a46fb823149a37f112a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a089e0e48c24d55b9076f7696e4c215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a891bf7e0a4a43408754930734041adc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6e6ae8eff2240e5a0863435885022a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9418a7c7d3d241daa7cddd3ba7c286d4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a0429493212409eb28baf3f09c85783",
              "IPY_MODEL_6d1118e5b22a456c920e8b76ccba2094",
              "IPY_MODEL_2f1b2a1a3edd400481620b937b98feb4"
            ]
          }
        },
        "9418a7c7d3d241daa7cddd3ba7c286d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a0429493212409eb28baf3f09c85783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c03032814f6a4316b1343fcd66e89e16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e7b6366c0444634a77a929d02a20878"
          }
        },
        "6d1118e5b22a456c920e8b76ccba2094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ae576cfcaf54e0c9b4a32c34339f6be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109801,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109801,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ce283551b494c20a0531b9b9b1a1c12"
          }
        },
        "2f1b2a1a3edd400481620b937b98feb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42f15fdc28b242b49af6bfbd961f9dc9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 109801/109801 [00:15&lt;00:00, 7265.20it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72308fb63fc2484bb92e76df8c03d95e"
          }
        },
        "c03032814f6a4316b1343fcd66e89e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e7b6366c0444634a77a929d02a20878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ae576cfcaf54e0c9b4a32c34339f6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ce283551b494c20a0531b9b9b1a1c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42f15fdc28b242b49af6bfbd961f9dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72308fb63fc2484bb92e76df8c03d95e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MR7C47HeoP8"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import math\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# import seaborn\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import random\n",
        "\n",
        "import sys\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "#np.random.seed(0) # make random consistent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0OrP6iQeoQB"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xlmfhvAQeoQB"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import signal\n",
        "\n",
        "\n",
        "class TimeoutException(Exception):  # Custom exception class\n",
        "    pass\n",
        "\n",
        "\n",
        "def timeout_handler(signum, frame):  # Custom signal handler\n",
        "    raise TimeoutException\n",
        "\n",
        "\n",
        "# Change the behavior of SIGALRM\n",
        "signal.signal(signal.SIGALRM, timeout_handler)\n",
        "\n",
        "\n",
        "class DataImporter:\n",
        "    \"\"\"\n",
        "    loads data set from the raw dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, log_template, dataset_folder_path, dataset_name, dataset_step=1,\n",
        "                 dataset_limit=100000, dataset_type='main', normal_indicator:str='-', aux_count=50000):\n",
        "        self.log_template = log_template  # a template containing <Token{n}> and <Message>\n",
        "        self.log_dataframe = None\n",
        "        self.dataset_folder_path: str = dataset_folder_path  # path to the dataset folder\n",
        "        self.dataset_name: str = dataset_name  # full name of raw dataset\n",
        "        self.step: int = dataset_step  # step taken to sample auxiliary dataset\n",
        "        self.log_template_regex: re = re.compile(r'')\n",
        "        self.log_template_headers: list[str] = []\n",
        "        self.limit: int = dataset_limit  # used for faster experiment only\n",
        "        self.dataset_type: str = dataset_type\n",
        "        self.normal_indicator: str = normal_indicator # a sign indicating the log line is anomaly\n",
        "        self.aux_count: int = aux_count\n",
        "        \n",
        "    def log_loader(self):\n",
        "        \"\"\"\n",
        "        read from IO stream and only take the actual log message based on template\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        log_messages = []\n",
        "        counter = 0\n",
        "        # there's uncommon encoding in dataset BG/P\n",
        "        with open(os.path.join(self.dataset_folder_path, self.dataset_name), 'r', encoding=\"latin-1\") as ds:\n",
        "            for line_no, line in enumerate(tqdm(ds)):\n",
        "                if line_no % self.step == 0:  # jump over steps\n",
        "                    try:\n",
        "                        #signal.alarm(30)\n",
        "\n",
        "                        try:\n",
        "                            match = self.log_template_regex.search(line.strip())\n",
        "                            message = [match.group(header) for header in self.log_template_headers]\n",
        "                            # if self.dataset_name=='Intrepid_RAS_0901_0908_scrubbed_small':\n",
        "                            #   print(message)\n",
        "                            log_messages.append(message)\n",
        "                            counter += 1\n",
        "                        except Exception:\n",
        "                            #print(\"Regex hang detected, skipping\")\n",
        "                            pass  # catastrophic backtracking\n",
        "                    except TimeoutException:\n",
        "                      pass\n",
        "                if line_no == self.limit:\n",
        "                    break\n",
        "        df = pandas.DataFrame(log_messages, columns=self.log_template_headers)\n",
        "        df.insert(0, 'LineId', None)\n",
        "        df['LineId'] = [i + 1 for i in range(counter)]\n",
        "        return df\n",
        "\n",
        "    def load(self):\n",
        "        self.log_template_matcher()\n",
        "\n",
        "        self.log_dataframe = self.log_loader()\n",
        "\n",
        "        # differentiate anomaly with normal log\n",
        "        log_messages= self.log_dataframe.Message\n",
        "        true_labels = np.where(self.log_dataframe.Token0.values == self.normal_indicator, 0, 1)\n",
        "\n",
        "        if self.dataset_type == 'auxiliary':\n",
        "            print(log_messages.iloc[true_labels.flatten() == 0].shape)\n",
        "            print(log_messages.iloc[true_labels.flatten() == 1])\n",
        "            df_normal = log_messages.iloc[true_labels.flatten() == 0].sample(n=self.aux_count).values\n",
        "            df_anomalies = log_messages.iloc[true_labels.flatten() == 1].sample(n=self.aux_count).values\n",
        "            return df_normal, df_anomalies\n",
        "        elif self.dataset_type == 'main':\n",
        "            return log_messages, true_labels\n",
        "\n",
        "    def load_special(self):\n",
        "        self.log_template_matcher()\n",
        "\n",
        "        self.log_dataframe = self.log_loader()\n",
        "\n",
        "        # differentiate anomaly with normal log\n",
        "        log_messages= self.log_dataframe.Message\n",
        "        true_labels = np.where(self.log_dataframe.Token0.values == self.normal_indicator, 0, 1)\n",
        "\n",
        "        if self.dataset_type == 'auxiliary':\n",
        "            df_normal = log_messages.iloc[true_labels.flatten() == 0].sample(n=self.aux_count).values\n",
        "            df_anomalies = log_messages.iloc[true_labels.flatten() == 1].sample(n=self.aux_count).values\n",
        "            return df_normal, df_anomalies\n",
        "        elif self.dataset_type == 'main':\n",
        "            return log_messages, true_labels\n",
        "\n",
        "    def log_template_matcher(self):\n",
        "        headers = []\n",
        "        template_chunks = re.split(r'(<[^<>]+>)', self.log_template)\n",
        "        expression = ''\n",
        "        for template_chunk_idx in range(len(template_chunks)):\n",
        "            if template_chunk_idx % 2 == 0:\n",
        "                splitter = re.sub(' +', '\\\\\\s+', template_chunks[template_chunk_idx])\n",
        "                expression += splitter\n",
        "            else:\n",
        "                header = template_chunks[template_chunk_idx].strip('<').strip('>')\n",
        "                expression += '(?P<%s>.+?)' % header  # change * from +\n",
        "                headers.append(header)\n",
        "        print(expression)\n",
        "        expression = re.compile('^' + expression + '$')\n",
        "\n",
        "        self.log_template_headers, self.log_template_regex = headers, expression\n",
        "\n",
        "    def pickle_processed(self, processed):\n",
        "        \"\"\"\n",
        "        pickle the df with only log message to a file\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        import pickle\n",
        "        pickle_path = os.path.join(self.dataset_folder_path, f'{self.dataset_name}_processed.pkl')\n",
        "        with open(pickle_path) as cached:\n",
        "            print(f\"Dumping processed dataset to pickle file path - {pickle_path}\")\n",
        "            pickle.dump(processed, cached)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZONBR_nueoQF"
      },
      "source": [
        "# Tokenize data \n",
        "\n",
        "Use NLTK and regex to remove http endpoints, stopwords, numerical words. Also turn to lower case.\n",
        "\n",
        "Finally add [CLS]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdK9nF_i5Emf",
        "outputId": "e9bbd947-16ac-48ad-fcef-ceb9bf5214c2"
      },
      "source": [
        "# Get NLTK data dicts\n",
        "import re\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VCYFpY8eoQG"
      },
      "source": [
        "\"\"\"\n",
        "Standard tokenizer + do what the paper says\n",
        "\"\"\"\n",
        "class DataTokenizer:\n",
        "    def __init__(self):\n",
        "        self.word2index = {'[PAD]': 0, '[CLS]': 1, '[MASK]': 2}\n",
        "        self.num_words = 3\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def tokenize(self, message):\n",
        "        # paper section IV: Tokenization processing\n",
        "        message = message.lower()\n",
        "        message = re.sub(r'/.*:', '', message, flags=re.MULTILINE)  # filter for endpoints\n",
        "        message = re.sub(r'/.*', '', message, flags=re.MULTILINE)\n",
        "        message = word_tokenize(message)                # remove non words\n",
        "        message = [word for word in message if word.isalpha()]  # remove numerical\n",
        "        message = [word for word in message if word not in self.stop_words]  # remove nltk common stopwords\n",
        "        #message = ['[CLS]'] + message  # add embedding token\n",
        "        for word_idx, word in enumerate(message):  # convert to value\n",
        "            if word not in self.word2index:\n",
        "                self.word2index[word] = self.num_words\n",
        "                self.num_words += 1\n",
        "            message[word_idx] = self.word2index[word]\n",
        "        return message\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN-auADW3eOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0834721-458e-4eaf-ed8c-c6337e9397d3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# special to google colab\n",
        "folder_path = 'drive/MyDrive/logsy_data/dataset'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3FFyiiSLnb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3b6ec10da5f54c80826b82ad0cc81ba2",
            "2948f509273b4addb1ea823f70b67987",
            "a641398ed6e8433a9b00178f64d237ae",
            "b72d7f8ee9454861934689700a8ac40c",
            "3bb6965c6f304014bcaed61a3ee9eaac",
            "f8d5d7b61b0f4188a955a1eb1bbcaa81",
            "e48ada6251dd47e0919c383155d63db8",
            "dc90096f9f304517b4e071b8328bb8a6",
            "44a70aa6102a4d5fa3dc75422a0f3bb5",
            "6aa2cba887cb4b8ab83aa9bd1e1caa5d",
            "ef5f69e4d2d34af684d3704a85162c71",
            "77b5ee5fe97949dc91f53608b9590723",
            "71f60ab4ae3b415b9ec647f89f107714",
            "9406c0652ca14151aecea74e567aa54e",
            "b72d182d2c4142efa918714560752704",
            "db1afe03fdca43ae917c3f8e6e199ac2",
            "878363b53b3d4db89ada90fede5e5faf",
            "84a7b1d8847045268430d2c78e083c6c",
            "be22fdc8455a44b4b90d5e21ab8a9bcc",
            "aed225dd8c714053bdbb23746ce5d5b0",
            "df5c4a1beca749c595f183bc98846f59",
            "2909aaf54de94629a4f3a375759162cd",
            "f6d18ea014e34037bcb9c3214d2429c0",
            "c2400531d05547a189b1cf38766a86de",
            "ebd2bf11397649489096663baac50465",
            "e75c231a996047df816fec48d31a5609",
            "10ec5681ea944f888a0b6049bab78389",
            "e452b68e45544615ba6d507fd9a63fb3",
            "43a1dd4548804615998a2292b26eba25",
            "014ca57216f544c59d9ef31b52649f00",
            "25886b0b95974750a40084141f355ea4",
            "f6513c9a0e504a8e9a76de2f1f41869b",
            "1170f4a9fb094400ab53ba4e044529aa"
          ]
        },
        "outputId": "9e687207-a415-41e9-f66a-32b2399769a6"
      },
      "source": [
        "# TODO move small dataset to same named but in dataset_small folder\n",
        "## loading bgp https://www.usenix.org/sites/default/files/4372-intrepid_ras_0901_0908_scrubbed.zip.tar 1.0GB; this dataset uses anomaly indicator 'FATAL'\n",
        "bgp_template = '<Token1> <Token2>          <Token3>       <Token4>                  <Token5>    <Token0> <Message>'\n",
        "name = 'Intrepid_RAS_0901_0908_scrubbed'  # BG/P\n",
        "\n",
        "# use special loader\n",
        "special_d, special_l = DataImporter(log_template=bgp_template, dataset_folder_path=folder_path,\n",
        "                                    dataset_name=name, dataset_step=1, dataset_type='main',dataset_limit=11000000, normal_indicator='FATAL').load_special()\n",
        "third_anomaly = special_d[special_l==0]\n",
        "print(f'\\nSuccessfully imported - {len(special_d)}  => {len(third_anomaly)} Messages from dataset at {os.path.join(folder_path, name)}\\n\\n')\n",
        "\n",
        "print(third_anomaly[1:5])\n",
        "# third_normal = third_data[label==1]\n",
        "# third_anomaly = third_data[label==0]\n",
        "## Use others as auxiliary \n",
        "### loading spirit http://0b4af6cdc2f0c5998459-c0245c5c937c5dedcca3f1764ecc9b2f.r43.cf2.rackcdn.com/hpc4/spirit2.gz\n",
        "#### big one so step should be bigger, 39GB of data; this dataset uses anomaly indicator '-'\n",
        "spirit_template = '<Token0> <Token1> <Token2> <Token3> <Token4> <Token5> <Token6> <Token7> <Message>'\n",
        "#name = 'spirit2'\n",
        "name = 'spirit_small'\n",
        "dataset_limit = 6000000\n",
        "first_normal, first_anomaly = DataImporter(log_template=spirit_template, dataset_folder_path=folder_path,\n",
        "                                    dataset_name=name, dataset_step=3, dataset_type='auxiliary',dataset_limit=dataset_limit, normal_indicator='-', aux_count=int(dataset_limit*0.02)).load()\n",
        "print(f'\\nSuccessfully imported - {len(first_normal)} => {len(first_anomaly)} Messages from dataset at {os.path.join(folder_path, name)}\\n\\n')\n",
        "print(first_anomaly[1:5])\n",
        "### loading liberty http://0b4af6cdc2f0c5998459-c0245c5c937c5dedcca3f1764ecc9b2f.r43.cf2.rackcdn.com/hpc4/liberty2.gz\n",
        "### 30GB not used yet\n",
        "...\n",
        "\n",
        "# thunderbird_template = '<Token0> <Token1> <Token2> <Token3> <Token4> <Token5> <Token6> <Token7> <Token8>(\\[<Token9>\\])?: <Message>'\n",
        "\n",
        "# name = 'tbird2_small'  # original dataset is too big, limit to 5,000,000 rows\n",
        "# second_normal, second_anomaly = DataImporter(log_template=thunderbird_template, dataset_folder_path=folder_path,\n",
        "#                                     dataset_name=name, dataset_step=1, dataset_type='auxiliary',dataset_limit=dataset_limit, normal_indicator='-', aux_count=int(dataset_limit*0.02)).load()\n",
        "# print(f'\\nSuccessfully imported - {len(second_normal)} => {len(second_anomaly)} Messages from dataset at {os.path.join(folder_path, name)}\\n\\n')\n",
        "\n",
        "\n",
        "\n",
        "### BG/L http://0b4af6cdc2f0c5998459-c0245c5c937c5dedcca3f1764ecc9b2f.r43.cf2.rackcdn.com/hpc4/bgl2.gz 0.72GB\n",
        "bgl_template = '<Token0> <Token1> <Token2> <Token3> <Token4> <Token5> <Token6> <Token7> <Token8> <Message>'  # bgl style token template\n",
        "name = 'bgl2'  # BG/P\n",
        "\n",
        "second_normal, second_anomaly = DataImporter(log_template=bgl_template, dataset_folder_path=folder_path,\n",
        "                                    dataset_name=name, dataset_step=1, dataset_type='auxiliary', dataset_limit=5000000, normal_indicator='-', aux_count=int(dataset_limit*0.02)).load()\n",
        "print(f'\\nSuccessfully imported - {len(second_normal)} => {len(second_anomaly)} Messages from dataset at {os.path.join(folder_path, name)}\\n\\n')\n",
        "print(second_anomaly[1:5])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(?P<Token1>.+?)\\s+(?P<Token2>.+?)\\s+(?P<Token3>.+?)\\s+(?P<Token4>.+?)\\s+(?P<Token5>.+?)\\s+(?P<Token0>.+?)\\s+(?P<Message>.+?)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b6ec10da5f54c80826b82ad0cc81ba2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Successfully imported - 2834486  => 30064 Messages from dataset at drive/MyDrive/logsy_data/dataset/Intrepid_RAS_0901_0908_scrubbed\n",
            "\n",
            "\n",
            "8425    2009-01-08-07.41.39.355367 -                  ...\n",
            "8479    2009-01-08-15.42.37.563676 -                  ...\n",
            "8499    2009-01-08-16.12.46.273384 -                  ...\n",
            "8530    2009-01-08-17.45.27.669492 -                  ...\n",
            "Name: Message, dtype: object\n",
            "(?P<Token0>.+?)\\s+(?P<Token1>.+?)\\s+(?P<Token2>.+?)\\s+(?P<Token3>.+?)\\s+(?P<Token4>.+?)\\s+(?P<Token5>.+?)\\s+(?P<Token6>.+?)\\s+(?P<Token7>.+?)\\s+(?P<Message>.+?)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77b5ee5fe97949dc91f53608b9590723",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1411563,)\n",
            "2                   kernel: hda: drive not ready for command\n",
            "3                   kernel: hda: drive not ready for command\n",
            "4                 kernel: hda: status error: status=0x00 { }\n",
            "6                   kernel: hda: drive not ready for command\n",
            "7                 kernel: hda: status error: status=0x00 { }\n",
            "                                 ...                        \n",
            "1666582    pbs_mom: scan_for_exiting, system epilog faile...\n",
            "1666606    pbs_mom: scan_for_exiting, system epilog faile...\n",
            "1666628    pbs_mom: scan_for_exiting, system epilog faile...\n",
            "1666649    pbs_mom: scan_for_exiting, system epilog faile...\n",
            "1666654    pbs_mom: scan_for_exiting, system epilog faile...\n",
            "Name: Message, Length: 255100, dtype: object\n",
            "\n",
            "Successfully imported - 120000 => 120000 Messages from dataset at drive/MyDrive/logsy_data/dataset/spirit_small\n",
            "\n",
            "\n",
            "['kernel: hda: status error: status=0x00 { }'\n",
            " 'kernel: hda: status error: status=0x00 { }'\n",
            " 'kernel: hda: drive not ready for command'\n",
            " 'kernel: hda: status error: status=0x00 { }']\n",
            "(?P<Token0>.+?)\\s+(?P<Token1>.+?)\\s+(?P<Token2>.+?)\\s+(?P<Token3>.+?)\\s+(?P<Token4>.+?)\\s+(?P<Token5>.+?)\\s+(?P<Token6>.+?)\\s+(?P<Token7>.+?)\\s+(?P<Token8>.+?)\\s+(?P<Message>.+?)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6d18ea014e34037bcb9c3214d2429c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4364795,)\n",
            "4903       ddr: excessive soft failures, consider replaci...\n",
            "14143      ddr: excessive soft failures, consider replaci...\n",
            "14737      ciod: failed to read message prefix on control...\n",
            "14738      ciod: failed to read message prefix on control...\n",
            "14739      ciod: failed to read message prefix on control...\n",
            "                                 ...                        \n",
            "4713488        idoproxy communication failure: socket closed\n",
            "4713489        idoproxy communication failure: socket closed\n",
            "4713490        idoproxy communication failure: socket closed\n",
            "4713491        idoproxy communication failure: socket closed\n",
            "4713492        idoproxy communication failure: socket closed\n",
            "Name: Message, Length: 348698, dtype: object\n",
            "\n",
            "Successfully imported - 120000 => 120000 Messages from dataset at drive/MyDrive/logsy_data/dataset/bgl2\n",
            "\n",
            "\n",
            "['ciod: Error reading message prefix on CioStream socket to 172.16.96.116:36722, Link has been severed'\n",
            " 'data TLB error interrupt'\n",
            " 'Lustre mount FAILED : bglio636 : point /p/gb1'\n",
            " 'ciod: Error creating node map from file /home/auselton/bgl/64mps.sequential.mapfile: Resource temporarily unavailable']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSw2XK2BQPyH",
        "outputId": "635ee764-1ebd-4583-c573-181ef148cca0"
      },
      "source": [
        "##################### < THIS PART WORKS PROPERLY\n",
        "# concatenate the 3 auxiliary datasets\n",
        "concat_normal = [] # not needed, auxiliary data are all treated as anomalies\n",
        "print(third_anomaly)\n",
        "print(len(first_anomaly), len(second_anomaly), len(third_anomaly))\n",
        "concat_anomaly = np.append(first_anomaly, second_anomaly) \n",
        "concat_anomaly = np.append(concat_anomaly, third_anomaly)\n",
        "\n",
        "print(len(concat_anomaly))\n",
        "# sampling auxiliary data from concat # we have 300000 =int(dataset_limit*0.05)\n",
        "aux_anomalies = np.random.choice(concat_anomaly, size=250000, replace=False)\n",
        "print(aux_anomalies.shape)\n",
        "###\n",
        "# 12.5% is anomaly aux"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8310       2009-01-08-02.54.41.805715 -                  ...\n",
            "8425       2009-01-08-07.41.39.355367 -                  ...\n",
            "8479       2009-01-08-15.42.37.563676 -                  ...\n",
            "8499       2009-01-08-16.12.46.273384 -                  ...\n",
            "8530       2009-01-08-17.45.27.669492 -                  ...\n",
            "                                 ...                        \n",
            "2829445    2009-08-20-18.59.36.664765   0   _DIAGS_R07-M1...\n",
            "2829446    2009-08-20-18.59.37.086821   0   _DIAGS_R07-M1...\n",
            "2830363    2009-08-20-19.13.24.764997   0   _DIAGS_R06-M1...\n",
            "2830675    2009-08-20-19.13.57.839694   0   _DIAGS_R07-M1...\n",
            "2831541    2009-08-20-19.38.43.492988   0   _DIAGS_R04-M0...\n",
            "Name: Message, Length: 30064, dtype: object\n",
            "120000 120000 30064\n",
            "270064\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427,
          "referenced_widgets": [
            "bc343d73dfa14543a81d2bd01523eca2",
            "003189f2331f4256bbb4beb58a4aa1ab",
            "91350cefadca44de9307f88c6176451b",
            "51e48d5d6a56482e9bb020039b4cf40c",
            "884c79a828ac4c178801cd9a677c9acd",
            "302e3cb8fcf442c48df873e077309616",
            "52d16e27a3294efaa9c314211387bb42",
            "72dd71470a4c48b7abd8811f106df893",
            "09d25232d79a46fb823149a37f112a04",
            "8a089e0e48c24d55b9076f7696e4c215",
            "a891bf7e0a4a43408754930734041adc"
          ]
        },
        "id": "5j59cDcT5Rsr",
        "outputId": "3ca62541-b466-4db7-94e3-38b0df003f69"
      },
      "source": [
        "############################ Loading main data and auxiliary data (for testing purposes use small version)\n",
        "## use tbird2 as main - currently using BG/L\n",
        "\n",
        "# ### BG/L http://0b4af6cdc2f0c5998459-c0245c5c937c5dedcca3f1764ecc9b2f.r43.cf2.rackcdn.com/hpc4/bgl2.gz 0.72GB\n",
        "# bgl_template = '<Token0> <Token1> <Token2> <Token3> <Token4> <Token5> <Token6> <Token7> <Token8> <Message>'  # bgl style token template\n",
        "# name = 'bgl' \n",
        "\n",
        "# log_messages, labels = DataImporter(log_template=bgl_template, dataset_folder_path=folder_path,\n",
        "#                                     dataset_name=name, dataset_step=1, dataset_type='main', dataset_limit=5000000, normal_indicator='-', aux_count=int(dataset_limit*0.02)).load()\n",
        "# print(f'\\nSuccessfully imported - {len(second_normal)} => {len(second_anomaly)} Messages from dataset at {os.path.join(folder_path, name)}\\n\\n')\n",
        "\n",
        "\n",
        "thunderbird_template = '<Token0> <Token1> <Token2> <Token3> <Token4> <Token5> <Token6> <Token7> <Token8>(\\[<Token9>\\])?: <Message>'\n",
        "\n",
        "name = 'tbird2_medium_200m_40step'  # original dataset is too big, limit to 5,000,000 rows\n",
        "log_messages, labels = DataImporter(log_template=thunderbird_template, dataset_folder_path=folder_path,\n",
        "                                    dataset_name=name, dataset_step=1, dataset_type='main',dataset_limit=5000000, normal_indicator='-', aux_count=int(dataset_limit*0.02)).load()\n",
        "print(f'\\nSuccessfully imported - {len(log_messages)} => {len(labels)} Messages from dataset at {os.path.join(folder_path, name)}\\n\\n')\n",
        "\n",
        "\n",
        "print(log_messages)\n",
        "print(log_messages.shape)\n",
        "print(labels.shape)\n",
        "labels = labels.reshape(-1, 1) # reshape\n",
        "print(labels.shape)\n",
        "print(labels[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(?P<Token0>.+?)\\s+(?P<Token1>.+?)\\s+(?P<Token2>.+?)\\s+(?P<Token3>.+?)\\s+(?P<Token4>.+?)\\s+(?P<Token5>.+?)\\s+(?P<Token6>.+?)\\s+(?P<Token7>.+?)\\s+(?P<Token8>.+?)(\\[(?P<Token9>.+?)\\])?:\\s+(?P<Message>.+?)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc343d73dfa14543a81d2bd01523eca2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Successfully imported - 99801 => 99801 Messages from dataset at drive/MyDrive/logsy_data/dataset/tbird2_medium_200m_40step\n",
            "\n",
            "\n",
            "0                     tftp: client does not accept options\n",
            "1                     tftp: client does not accept options\n",
            "2        warning: unable to look up public/pickup: No s...\n",
            "3                     tftp: client does not accept options\n",
            "4                  session opened for user root by (uid=0)\n",
            "                               ...                        \n",
            "99796                          Got trap from peer on fd 13\n",
            "99797    Instrumentation Service EventID: 1052 Temperat...\n",
            "99798    [ib_sm_discovery.c:1103]: Failed discover node...\n",
            "99799                          Got trap from peer on fd 13\n",
            "99800    [ib_sm_discovery.c:470]: Failed to GetNodeInfo...\n",
            "Name: Message, Length: 99801, dtype: object\n",
            "(99801,)\n",
            "(99801,)\n",
            "(99801, 1)\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IS6Nh6GSxvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89358936-7c86-484a-a7d1-b9bf9f912e39"
      },
      "source": [
        "#append the anomalies to the full data\n",
        "concat_messages = np.append(log_messages.values.reshape(-1,1), aux_anomalies.reshape(-1,1), axis=0)\n",
        "print(labels.shape) \n",
        "print(np.ones(len(aux_anomalies)).shape)\n",
        "concat_labels = np.append(labels,  np.ones(len(aux_anomalies)).reshape(-1,1), axis=0).flatten()\n",
        "concat_messages.shape, concat_labels.shape\n",
        "import collections\n",
        "collections.Counter(concat_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(99801, 1)\n",
            "(10000,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0.0: 95732, 1.0: 14069})"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231,
          "referenced_widgets": [
            "b6e6ae8eff2240e5a0863435885022a1",
            "9418a7c7d3d241daa7cddd3ba7c286d4",
            "4a0429493212409eb28baf3f09c85783",
            "6d1118e5b22a456c920e8b76ccba2094",
            "2f1b2a1a3edd400481620b937b98feb4",
            "c03032814f6a4316b1343fcd66e89e16",
            "8e7b6366c0444634a77a929d02a20878",
            "5ae576cfcaf54e0c9b4a32c34339f6be",
            "7ce283551b494c20a0531b9b9b1a1c12",
            "42f15fdc28b242b49af6bfbd961f9dc9",
            "72308fb63fc2484bb92e76df8c03d95e"
          ]
        },
        "id": "eHBQmRtfSNlH",
        "outputId": "519000b6-90ec-411d-8321-8c3a1091e0f5"
      },
      "source": [
        "############################# Tokenize full data\n",
        "from tqdm.notebook import trange\n",
        "print(f'Starting to tokenize messages, pushing result to pickle(TODO)')\n",
        "tokenizer = DataTokenizer()\n",
        "data_tokenized = []\n",
        "print(\"##################### Data Shape ##############\")\n",
        "print(concat_messages.shape, concat_labels.shape)\n",
        "print(\"##################### Data Shape End ##############\")\n",
        "df_len = int(concat_messages.shape[0])\n",
        "for i in trange(df_len):\n",
        "    tokenized = tokenizer.tokenize(concat_messages[i][0])\n",
        "    data_tokenized.append(tokenized)\n",
        "\n",
        "data_tokenized = np.asanyarray(data_tokenized)\n",
        "print(data_tokenized.shape)\n",
        "\n",
        "import pickle\n",
        "print(f\"vocab size - {tokenizer.num_words}\")\n",
        "vocab_size = tokenizer.num_words\n",
        "print(folder_path)\n",
        "with open(f'{folder_path}/pickled_concat', 'wb') as message_file:\n",
        "    pickle.dump(data_tokenized, message_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to tokenize messages, pushing result to pickle(TODO)\n",
            "##################### Data Shape ##############\n",
            "(109801, 1) (109801,)\n",
            "##################### Data Shape End ##############\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6e6ae8eff2240e5a0863435885022a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/109801 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(109801,)\n",
            "vocab size - 1102\n",
            "drive/MyDrive/logsy_data/dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS2Zk5K3yPY6"
      },
      "source": [
        "# Split data to train set and test set\n",
        "\n",
        "variables: \n",
        "\n",
        "    data_tokenized: all data\n",
        "\n",
        "    labels : all labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_6L14hnNzt5"
      },
      "source": [
        "# load from file directly without tokenization\n",
        "\n",
        "with open(f'{folder_path}/pickled_concat','rb') as p:\n",
        "  data_tokenized = pickle.load(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG7xsivORHhD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb574d08-5346-4a36-cb9a-770924bd2edc"
      },
      "source": [
        "ratio = 0.5\n",
        "train_size = int(len(log_messages) * ratio)\n",
        "test_size = int(len(log_messages) * (1-ratio))\n",
        "print(train_size, test_size)\n",
        "print(train_size/len(log_messages))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49900 49900\n",
            "0.49999499003016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS_LFdrYRNCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96e2dc7-f3e1-48ed-bf63-ba9eed5aadf1"
      },
      "source": [
        "# def split_data(data, labels, train_size, test_size):\n",
        "#     print(train_size, test_size)\n",
        "#     x_train, = np.append(data[:train_size][labels[:train_size]==0], data[train_size:])\n",
        "#     y_train = labels[:train_size][labels[:train_size]==0]\n",
        "#     x_test =  data[train_size:][labels[train_size:]==1]\n",
        "#     y_test = labels[train_size:][labels[train_size:]==1]\n",
        "#     print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "#     return x_train, y_train, x_test, y_test\n",
        "\n",
        "# #from sklearn.model_selection import train_test_split\n",
        "# #x_train, y_train, x_test, y_test = train_test_split(pd, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# x_train, y_train, x_test, y_test = split_data(pd, labels, train_size, test_size)\n",
        "# len(x_train), len(x_val), len(y_train), len(y_val)\n",
        "from collections import Counter\n",
        "collections.Counter(concat_labels)\n",
        "#print(Counter(labels))  # target set\n",
        "print(data_tokenized.shape) # tokenized concat shape\n",
        "\n",
        "print(len(log_messages))\n",
        "print(len(concat_labels))\n",
        "\n",
        "target_size = len(log_messages)\n",
        "a = collections.Counter(concat_labels[target_size:])\n",
        "print(a)\n",
        "x_train = np.append(data_tokenized[:train_size][concat_labels[:train_size]==0], data_tokenized[target_size:],axis=0)\n",
        "y_train = np.append(concat_labels[:train_size][concat_labels[:train_size]==0].flatten(), concat_labels[target_size:].flatten(),axis=0)\n",
        "x_test = data_tokenized[train_size:target_size]\n",
        "y_test = concat_labels[train_size:target_size]\n",
        "# print(x_train, y_train, x_test, y_test )\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "print(collections.Counter(y_train))\n",
        "print(collections.Counter(y_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(109801,)\n",
            "99801\n",
            "109801\n",
            "Counter({1.0: 10000})\n",
            "(59740,) (59740,) (49901,) (49901,)\n",
            "Counter({0.0: 49740, 1.0: 10000})\n",
            "Counter({0.0: 45992, 1.0: 3909})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCrtRFxDt5fO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6493fe2-9e94-41c6-ecfd-6314c7ce3d74"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=50, truncating=\"post\", padding=\"post\") \n",
        "\n",
        "x_test = pad_sequences(x_test, maxlen=50, truncating=\"post\", padding=\"post\") \n",
        "print(x_train.shape, x_test.shape)\n",
        "print(x_train[0])\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "## padding masks\n",
        "x_train_masks = tf.equal(x_train, 0)\n",
        "x_test_masks = tf.equal(x_test, 0)\n",
        "print(x_train_masks,x_test_masks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59740, 50) (49901, 50)\n",
            "[3 4 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(59740, 50) (59740,) (49901, 50) (49901,)\n",
            "tf.Tensor(\n",
            "[[False False False ...  True  True  True]\n",
            " [False False False ...  True  True  True]\n",
            " [False False False ...  True  True  True]\n",
            " ...\n",
            " [False False False ...  True  True  True]\n",
            " [False False False ...  True  True  True]\n",
            " [False False False ...  True  True  True]], shape=(59740, 50), dtype=bool) tf.Tensor(\n",
            "[[False False False ...  True  True  True]\n",
            " [False False  True ...  True  True  True]\n",
            " [False False False ...  True  True  True]\n",
            " ...\n",
            " [False False False ...  True  True  True]\n",
            " [False False False ...  True  True  True]\n",
            " [False False False ...  True  True  True]], shape=(49901, 50), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOzM3xQIpPGu"
      },
      "source": [
        "# Transformer models\n",
        "\n",
        "## An open-source implementation of standard transformer with multi-head attention, for comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEFH4KuKlNWw"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class Embedding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, vocab_size, model_dim, **kwargs):\n",
        "        self._vocab_size = vocab_size\n",
        "        self._model_dim = model_dim\n",
        "        super(Embedding, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.embeddings = self.add_weight(\n",
        "            shape=(self._vocab_size, self._model_dim),\n",
        "            initializer='glorot_uniform',\n",
        "            name=\"embeddings\")\n",
        "        super(Embedding, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if K.dtype(inputs) != 'int32':\n",
        "            inputs = K.cast(inputs, 'int32')\n",
        "        embeddings = K.gather(self.embeddings, inputs)\n",
        "        embeddings *= self._model_dim ** 0.5 # Scale\n",
        "        return embeddings\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "\n",
        "        return input_shape + (self._model_dim,)\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class ScaledDotProductAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, masking=True, future=False, dropout_rate=0., **kwargs):\n",
        "        self._masking = masking\n",
        "        self._future = future\n",
        "        self._dropout_rate = dropout_rate\n",
        "        self._masking_num = -2**32+1\n",
        "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def mask(self, inputs, masks):\n",
        "        masks = K.cast(masks, 'float32')\n",
        "        masks = K.tile(masks, [K.shape(inputs)[0] // K.shape(masks)[0], 1])\n",
        "        masks = K.expand_dims(masks, 1)\n",
        "        outputs = inputs + masks * self._masking_num\n",
        "        return outputs\n",
        "    \n",
        "    def future_mask(self, inputs):\n",
        "        diag_vals = tf.ones_like(inputs[0, :, :])\n",
        "        tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()  \n",
        "        future_masks = tf.tile(tf.expand_dims(tril, 0), [tf.shape(inputs)[0], 1, 1])\n",
        "        paddings = tf.ones_like(future_masks) * self._masking_num\n",
        "        outputs = tf.where(tf.equal(future_masks, 0), paddings, inputs)\n",
        "        return outputs\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if self._masking:\n",
        "            assert len(inputs) == 4, \"inputs should be set [queries, keys, values, masks].\"\n",
        "            queries, keys, values, masks = inputs\n",
        "        else:\n",
        "            assert len(inputs) == 3, \"inputs should be set [queries, keys, values].\"\n",
        "            queries, keys, values = inputs\n",
        "\n",
        "        if K.dtype(queries) != 'float32':  queries = K.cast(queries, 'float32')\n",
        "        if K.dtype(keys) != 'float32':  keys = K.cast(keys, 'float32')\n",
        "        if K.dtype(values) != 'float32':  values = K.cast(values, 'float32')\n",
        "\n",
        "        matmul = K.batch_dot(queries, tf.transpose(keys, [0, 2, 1])) # MatMul\n",
        "        scaled_matmul = matmul / int(queries.shape[-1]) ** 0.5  # Scale\n",
        "        if self._masking:\n",
        "            scaled_matmul = self.mask(scaled_matmul, masks) # Mask(opt.)\n",
        "\n",
        "        if self._future:\n",
        "            scaled_matmul = self.future_mask(scaled_matmul)\n",
        "\n",
        "        softmax_out = K.softmax(scaled_matmul) # SoftMax\n",
        "        # Dropout\n",
        "        out = K.dropout(softmax_out, self._dropout_rate)\n",
        "        \n",
        "        outputs = K.batch_dot(out, values)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, n_heads, head_dim, dropout_rate=.1, masking=True, future=False, trainable=True, **kwargs):\n",
        "        self._n_heads = n_heads\n",
        "        self._head_dim = head_dim\n",
        "        self._dropout_rate = dropout_rate\n",
        "        self._masking = masking\n",
        "        self._future = future\n",
        "        self._trainable = trainable\n",
        "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self._weights_queries = self.add_weight(\n",
        "            shape=(input_shape[0][-1], self._n_heads * self._head_dim),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=self._trainable,\n",
        "            name='weights_queries')\n",
        "        self._weights_keys = self.add_weight(\n",
        "            shape=(input_shape[1][-1], self._n_heads * self._head_dim),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=self._trainable,\n",
        "            name='weights_keys')\n",
        "        self._weights_values = self.add_weight(\n",
        "            shape=(input_shape[2][-1], self._n_heads * self._head_dim),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=self._trainable,\n",
        "            name='weights_values')\n",
        "        super(MultiHeadAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if self._masking:\n",
        "            assert len(inputs) == 4, \"inputs should be set [queries, keys, values, masks].\"\n",
        "            queries, keys, values, masks = inputs\n",
        "        else:\n",
        "            assert len(inputs) == 3, \"inputs should be set [queries, keys, values].\"\n",
        "            queries, keys, values = inputs\n",
        "        \n",
        "        queries_linear = K.dot(queries, self._weights_queries) \n",
        "        keys_linear = K.dot(keys, self._weights_keys)\n",
        "        values_linear = K.dot(values, self._weights_values)\n",
        "\n",
        "        queries_multi_heads = tf.concat(tf.split(queries_linear, self._n_heads, axis=2), axis=0)\n",
        "        keys_multi_heads = tf.concat(tf.split(keys_linear, self._n_heads, axis=2), axis=0)\n",
        "        values_multi_heads = tf.concat(tf.split(values_linear, self._n_heads, axis=2), axis=0)\n",
        "        \n",
        "        if self._masking:\n",
        "            att_inputs = [queries_multi_heads, keys_multi_heads, values_multi_heads, masks]\n",
        "        else:\n",
        "            att_inputs = [queries_multi_heads, keys_multi_heads, values_multi_heads]\n",
        "            \n",
        "        attention = ScaledDotProductAttention(\n",
        "            masking=self._masking, future=self._future, dropout_rate=self._dropout_rate)\n",
        "        att_out = attention(att_inputs)\n",
        "\n",
        "        outputs = tf.concat(tf.split(att_out, self._n_heads, axis=0), axis=2)\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class PositionEncoding(Layer):\n",
        "\n",
        "    def __init__(self, model_dim, **kwargs):\n",
        "        self._model_dim = model_dim\n",
        "        super(PositionEncoding, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        seq_length = inputs.shape[1]\n",
        "        position_encodings = np.zeros((seq_length, self._model_dim))\n",
        "        for pos in range(seq_length):\n",
        "            for i in range(self._model_dim):\n",
        "                position_encodings[pos, i] = pos / np.power(10000, (i-i%2) / self._model_dim)\n",
        "        position_encodings[:, 0::2] = np.sin(position_encodings[:, 0::2]) # 2i\n",
        "        position_encodings[:, 1::2] = np.cos(position_encodings[:, 1::2]) # 2i+1\n",
        "        position_encodings = K.cast(position_encodings, 'float32')\n",
        "        return position_encodings\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class Add(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Add, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        input_a, input_b = inputs\n",
        "        return input_a + input_b\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class PositionWiseFeedForward(Layer):\n",
        "    \n",
        "    def __init__(self, model_dim, inner_dim, trainable=True, **kwargs):\n",
        "        self._model_dim = model_dim\n",
        "        self._inner_dim = inner_dim\n",
        "        self._trainable = trainable\n",
        "        super(PositionWiseFeedForward, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.weights_inner = self.add_weight(\n",
        "            shape=(input_shape[-1], self._inner_dim),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=self._trainable,\n",
        "            name=\"weights_inner\")\n",
        "        self.weights_out = self.add_weight(\n",
        "            shape=(self._inner_dim, self._model_dim),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=self._trainable,\n",
        "            name=\"weights_out\")\n",
        "        self.bias_inner = self.add_weight(\n",
        "            shape=(self._inner_dim,),\n",
        "            initializer='uniform',\n",
        "            trainable=self._trainable,\n",
        "            name=\"bias_inner\")\n",
        "        self.bias_out = self.add_weight(\n",
        "            shape=(self._model_dim,),\n",
        "            initializer='uniform',\n",
        "            trainable=self._trainable,\n",
        "            name=\"bias_out\")\n",
        "        super(PositionWiseFeedForward, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if K.dtype(inputs) != 'float32':\n",
        "            inputs = K.cast(inputs, 'float32')\n",
        "        inner_out = K.relu(K.dot(inputs, self.weights_inner) + self.bias_inner)\n",
        "        outputs = K.dot(inner_out, self.weights_out) + self.bias_out\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return self._model_dim\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class LayerNormalization(Layer):\n",
        "\n",
        "    def __init__(self, epsilon=1e-8, **kwargs):\n",
        "        self._epsilon = epsilon\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.beta = self.add_weight(\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='zero',\n",
        "            name='beta')\n",
        "        self.gamma = self.add_weight(\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='one',\n",
        "            name='gamma')\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        mean, variance = tf.nn.moments(inputs, [-1], keepdims=True)\n",
        "        normalized = (inputs - mean) / ((variance + self._epsilon) ** 0.5)\n",
        "        outputs = self.gamma * normalized + self.beta\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class Transformer(Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 model_dim,\n",
        "                 n_heads=8,\n",
        "                 encoder_stack=6,\n",
        "                 decoder_stack=6,\n",
        "                 feed_forward_size=2048,\n",
        "                 dropout_rate=0.1,\n",
        "                 **kwargs):\n",
        "\n",
        "        self._vocab_size = vocab_size\n",
        "        self._model_dim = model_dim\n",
        "        self._n_heads = n_heads\n",
        "        self._encoder_stack = encoder_stack\n",
        "        self._decoder_stack = decoder_stack\n",
        "        self._feed_forward_size = feed_forward_size\n",
        "        self._dropout_rate = dropout_rate\n",
        "        super(Transformer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.embeddings = self.add_weight(\n",
        "            shape=(self._vocab_size, self._model_dim),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True,\n",
        "            name=\"embeddings\")\n",
        "        self.EncoderPositionEncoding = PositionEncoding(self._model_dim)\n",
        "        self.EncoderMultiHeadAttentions = [\n",
        "            MultiHeadAttention(self._n_heads, self._model_dim // self._n_heads)\n",
        "            for _ in range(self._encoder_stack)\n",
        "        ]\n",
        "        self.EncoderLayerNorms0 = [\n",
        "            LayerNormalization()\n",
        "            for _ in range(self._encoder_stack)\n",
        "        ]\n",
        "        self.EncoderPositionWiseFeedForwards = [\n",
        "            PositionWiseFeedForward(self._model_dim, self._feed_forward_size)\n",
        "            for _ in range(self._encoder_stack)\n",
        "        ]\n",
        "        self.EncoderLayerNorms1 = [\n",
        "            LayerNormalization()\n",
        "            for _ in range(self._encoder_stack)\n",
        "        ]\n",
        "        self.DecoderPositionEncoding = PositionEncoding(self._model_dim)\n",
        "        self.DecoderMultiHeadAttentions0 = [\n",
        "            MultiHeadAttention(self._n_heads, self._model_dim // self._n_heads, future=True)\n",
        "            for _ in range(self._decoder_stack)\n",
        "        ]\n",
        "        self.DecoderLayerNorms0 = [\n",
        "            LayerNormalization()\n",
        "            for _ in range(self._decoder_stack)\n",
        "        ]\n",
        "        self.DecoderMultiHeadAttentions1 = [\n",
        "            MultiHeadAttention(self._n_heads, self._model_dim // self._n_heads)\n",
        "            for _ in range(self._decoder_stack)\n",
        "        ]\n",
        "        self.DecoderLayerNorms1 = [\n",
        "            LayerNormalization()\n",
        "            for _ in range(self._decoder_stack)\n",
        "        ]\n",
        "        self.DecoderPositionWiseFeedForwards = [\n",
        "            PositionWiseFeedForward(self._model_dim, self._feed_forward_size)\n",
        "            for _ in range(self._decoder_stack)\n",
        "        ]\n",
        "        self.DecoderLayerNorms2 = [\n",
        "            LayerNormalization()\n",
        "            for _ in range(self._decoder_stack)\n",
        "        ]\n",
        "        super(Transformer, self).build(input_shape)\n",
        "        \n",
        "    def encoder(self, inputs):\n",
        "        if K.dtype(inputs) != 'int32':\n",
        "            inputs = K.cast(inputs, 'int32')\n",
        "\n",
        "        masks = K.equal(inputs, 0)\n",
        "        # Embeddings\n",
        "        embeddings = K.gather(self.embeddings, inputs)\n",
        "        embeddings *= self._model_dim ** 0.5 # Scale\n",
        "        # Position Encodings\n",
        "        position_encodings = self.EncoderPositionEncoding(embeddings)\n",
        "        # Embeddings + Position-encodings\n",
        "        encodings = embeddings + position_encodings\n",
        "        # Dropout\n",
        "        encodings = K.dropout(encodings, self._dropout_rate)\n",
        "\n",
        "        for i in range(self._encoder_stack):\n",
        "            # Multi-head-Attention\n",
        "            attention = self.EncoderMultiHeadAttentions[i]\n",
        "            attention_input = [encodings, encodings, encodings, masks]\n",
        "            attention_out = attention(attention_input)\n",
        "            # Add & Norm\n",
        "            attention_out += encodings\n",
        "            attention_out = self.EncoderLayerNorms0[i](attention_out)\n",
        "            # Feed-Forward\n",
        "            ff = self.EncoderPositionWiseFeedForwards[i]\n",
        "            ff_out = ff(attention_out)\n",
        "            # Add & Norm\n",
        "            ff_out += attention_out\n",
        "            encodings = self.EncoderLayerNorms1[i](ff_out)\n",
        "\n",
        "        return encodings, masks\n",
        "\n",
        "    def decoder(self, inputs):\n",
        "        decoder_inputs, encoder_encodings, encoder_masks = inputs\n",
        "        if K.dtype(decoder_inputs) != 'int32':\n",
        "            decoder_inputs = K.cast(decoder_inputs, 'int32')\n",
        "\n",
        "        decoder_masks = K.equal(decoder_inputs, 0)\n",
        "        # Embeddings\n",
        "        embeddings = K.gather(self.embeddings, decoder_inputs)\n",
        "        embeddings *= self._model_dim ** 0.5 # Scale\n",
        "        # Position Encodings\n",
        "        position_encodings = self.DecoderPositionEncoding(embeddings)\n",
        "        # Embeddings + Position-encodings\n",
        "        encodings = embeddings + position_encodings\n",
        "        # Dropout\n",
        "        encodings = K.dropout(encodings, self._dropout_rate)\n",
        "        \n",
        "        for i in range(self._decoder_stack):\n",
        "            # Masked-Multi-head-Attention\n",
        "            masked_attention = self.DecoderMultiHeadAttentions0[i]\n",
        "            masked_attention_input = [encodings, encodings, encodings, decoder_masks]\n",
        "            masked_attention_out = masked_attention(masked_attention_input)\n",
        "            # Add & Norm\n",
        "            masked_attention_out += encodings\n",
        "            masked_attention_out = self.DecoderLayerNorms0[i](masked_attention_out)\n",
        "\n",
        "            # Multi-head-Attention\n",
        "            attention = self.DecoderMultiHeadAttentions1[i]\n",
        "            attention_input = [masked_attention_out, encoder_encodings, encoder_encodings, encoder_masks]\n",
        "            attention_out = attention(attention_input)\n",
        "            # Add & Norm\n",
        "            attention_out += masked_attention_out\n",
        "            attention_out = self.DecoderLayerNorms1[i](attention_out)\n",
        "\n",
        "            # Feed-Forward\n",
        "            ff = self.DecoderPositionWiseFeedForwards[i]\n",
        "            ff_out = ff(attention_out)\n",
        "            # Add & Norm\n",
        "            ff_out += attention_out\n",
        "            encodings = self.DecoderLayerNorms2[i](ff_out)\n",
        "\n",
        "        # Pre-SoftMax Embeddings \n",
        "        linear_projection = K.dot(encodings, K.transpose(self.embeddings))\n",
        "        outputs = K.softmax(linear_projection)\n",
        "        return outputs\n",
        "\n",
        "    def call(self, encoder_inputs, decoder_inputs, **kwargs):\n",
        "        encoder_encodings, encoder_masks = self.encoder(encoder_inputs)\n",
        "        encoder_outputs = self.decoder([decoder_inputs, encoder_encodings, encoder_masks])\n",
        "        return encoder_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0][0], input_shape[0][1], self._vocab_size\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"vocab_size\": self._vocab_size,\n",
        "            \"model_dim\": self._model_dim,\n",
        "            \"n_heads\": self._n_heads,\n",
        "            \"encoder_stack\": self._encoder_stack,\n",
        "            \"decoder_stack\": self._decoder_stack,\n",
        "            \"feed_forward_size\": self._feed_forward_size,\n",
        "            \"dropout_rate\": self._dropout_rate\n",
        "        }\n",
        "        base_config = super(Transformer, self).get_config()\n",
        "        return {**base_config, **config}\n",
        "\n",
        "\n",
        "class Noam(Callback):\n",
        "\n",
        "    def __init__(self, model_dim, step_num=0, warmup_steps=4000, verbose=False):\n",
        "        self._model_dim = model_dim\n",
        "        self._step_num = step_num\n",
        "        self._warmup_steps = warmup_steps\n",
        "        self.verbose = verbose\n",
        "        super(Noam, self).__init__()\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        logs = logs or {}\n",
        "        init_lr = self._model_dim ** -.5 * self._warmup_steps ** -1.5\n",
        "        K.set_value(self.model.optimizer.lr, init_lr)\n",
        "\n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self._step_num += 1\n",
        "        lrate = self._model_dim ** -.5 * K.minimum(self._step_num ** -.5, self._step_num * self._warmup_steps ** -1.5)\n",
        "        K.set_value(self.model.optimizer.lr, lrate)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if self.verbose:\n",
        "            lrate = K.get_value(self.model.optimizer.lr)\n",
        "            print(f\"epoch {epoch} lr: {lrate}\")\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
        "    \n",
        "\n",
        "def label_smoothing(inputs, epsilon=0.1):\n",
        "    output_dim = inputs.shape[-1]\n",
        "    smooth_label = (1 - epsilon) * inputs + (epsilon / output_dim)\n",
        "    return smooth_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1heS-bZqeoQH"
      },
      "source": [
        "# Build Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl0gZmL1kyJx"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "# def recall_m(y_true, y_pred):\n",
        "#     y_pred = K.sum(K.square(y_pred), axis=1)\n",
        "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "#     recall = true_positives / (possible_positives + K.epsilon())\n",
        "#     return recall\n",
        "\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    # y_pred = K.sum(K.square(y_pred), axis=1)\n",
        "    # true_positives = K.sum(y_true)\n",
        "    # possible_positives = K.sum(K.round(K.clip(y_pred * y_true, 0 ,1)))\n",
        "    #y_pred = K.sum(K.square(y_pred), axis=1)\n",
        "    y_pred = K.sum(K.square(y_pred))\n",
        "\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    y_pred = K.sum(K.square(y_pred),axis=1)\n",
        "\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (predicted_positives + K.epsilon())\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    y_pred = K.sum(K.square(y_pred))\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def accuracy_m(y_true, y_pred):\n",
        "    y_pred = K.sum(K.square(y_pred))\n",
        "    acc = K.mean(y_true==K.round(y_pred))\n",
        "\n",
        "    return acc\n",
        "\n",
        "def create_model():\n",
        "  model_dim = 16\n",
        "  batch_size = 256\n",
        "  epochs = 10\n",
        "  max_len = 50\n",
        "  encoder_inputs = tf.keras.Input(shape=(max_len,), name='encoder_inputs')\n",
        "  decoder_inputs = tf.keras.Input(shape=(max_len,), name='decoder_inputs')\n",
        "  vocab_size =tokenizer.n_words\n",
        "  outputs = Transformer(\n",
        "      vocab_size, \n",
        "      model_dim, \n",
        "      n_heads=2, \n",
        "      encoder_stack=2,\n",
        "      decoder_stack=2, \n",
        "      feed_forward_size=16\n",
        "  )(encoder_inputs, decoder_inputs)\n",
        "  outputs = tf.keras.layers.GlobalAveragePooling1D()(outputs)\n",
        "  #outputs = tf.keras.layers.\n",
        "  #outputs = K.sum(K.square(outputs), axis=1)\n",
        "\n",
        "  # function = lambda x: K.sum(x, axis=1)\n",
        "  # outputs = tf.keras.layers.Lambda(function, output_shape=(None,1))(outputs)\n",
        "  # model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=outputs)\n",
        "  # outputs=tf.keras.activations.sigmoid(outputs)\n",
        "  model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=outputs)\n",
        "  return model\n",
        "\n",
        "# keract.get_activations(model, x, layer_names=None, nodes_to_evaluate=None, output_format='simple', nested=False, auto_compile=True)\n",
        "\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.98, epsilon=1e-9), \n",
        "#     loss='binary_crossentropy', metrics=['accuracy',recall_m, precision_m,f1_m], loss_weights = [0.3, 1.0])\n",
        "# learning rate decay for optmimizer\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001, # 0.0001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=1-0.001)\n",
        "# optimizer\n",
        "model_opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule,beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "def custom_loss_function(y_true, y_pred):\n",
        "   import torch\n",
        "   dist = K.sum(K.square(y_pred),axis=1)\n",
        "  #  print(f\"y_pred -==== {y_pred,y_true}\")\n",
        "  #  print(f\"y_pred - 0.0 {y_pred - 0.0}\")\n",
        "   #dist = torch.sum((y_pred[:,0,:] - 0) ** 2, dim=1)\n",
        "  #  loss = K.mean(y_pred,axis=1)\n",
        "   #  loss = K.mean((1-y_true)*K.sqrt(dist) - (y_true)*K.log(1-K.exp(-K.sqrt(dist))))\n",
        "   loss = K.mean((1-y_true)*K.square(dist) - (y_true)*K.log(1-K.exp(-K.square(dist))))\n",
        "   \n",
        "   return loss\n",
        "#model.compile(optimizer=model_opt, loss=\"binary_crossentropy\", metrics=['accuracy',recall_m, precision_m,f1_m],loss_weights = [0.3, 1.0]) #, loss_weights = [0.3, 1.0]\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model = create_model()\n",
        "model.compile(optimizer=model_opt, loss=custom_loss_function)#,loss_weights = [0.3, 1.0]) #, loss_weights = [0.3, 1.0]\n",
        "#model.compile(optimizer=model_opt, loss=custom_loss_function, metrics=[accuracy_m,recall_m,precision_m],loss_weights = [0.3, 1.0]) #, loss_weights = [0.3, 1.0]\n",
        "\n",
        "#es = EarlyStopping(patience=3)\n",
        "print(model.summary())\n",
        "model.fit([x_train, x_train_masks], y_train, \n",
        "    batch_size=batch_size, epochs=1 )#, validation_data=([x_test,x_test_masks],y_test)) # , callbacks=[es]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VAHxfh3qHlH"
      },
      "source": [
        "# Define spherical loss function and optimizer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ocRT4ZWt0VD"
      },
      "source": [
        "# Test Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-80frLb9pbOm"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\"\"\"## Implement a Transformer block as a layer\"\"\"\n",
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.05):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "\"\"\"## Implement embedding layer\n",
        "\n",
        "Two seperate embedding layers, one for tokens, one for token index (positions).\n",
        "\"\"\"\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n",
        "\n",
        "input_vocab_size = tokenizer.num_words #tokenizer.n_words # size of input data\n",
        "output_vocab_size = 2 # binary classficiation output: normal or anomaly data\n",
        "maxlen = 50  # max encoding position for encoder and decoder layer? \n",
        "embed_dim = 16  # Embedding size for each token\n",
        "num_heads = 2  # 2 Number of attention heads\n",
        "ff_dim = 16  # 16 Hidden layer size in feed forward network inside transformer\n",
        "dropout_rate = 0.05\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, input_vocab_size, embed_dim)\n",
        "\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "# x = layers.Dropout(dropout_rate)(x)\n",
        "# x = layers.Dense(20, activation=\"relu\")(x)\n",
        "# x = layers.Dropout(dropout_rate)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "# transformer model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# learning rate decay for optmimizer\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0001, # 0.0001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=1-0.001)\n",
        "# optimizer\n",
        "model_opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule,beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxsN-DDMfMIm"
      },
      "source": [
        "#loss_fun = SimpleLossCompute(model,criterion,model_opt)\n",
        "#model.compile(model_opt, \"sparse_categorical_crossentropy\", metrics=[\"accuracy\", recall_m, precision_m, f1_m],) # use our own loss\n",
        "model.compile(model_opt, loss = custom_loss_function, metrics=[\"accuracy\", recall_m, precision_m, f1_m], loss_weights = [0.3, 1.0]) # use our own loss\n",
        "#model.compile(model_opt, loss = 'binary_crossentropy', metrics=[\"accuracy\", recall_m, precision_m, f1_m],) # use our own loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDTIGk_ARhOo"
      },
      "source": [
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "# idx = np.random.choice(np.arange(len(x_train)), 1000000, replace=False)\n",
        "# x_train_small = x_train[idx]\n",
        "# y_train_small = y_train[idx]\n",
        "# idx_test = np.random.choice(np.arange(len(x_test)), 60000, replace=False)\n",
        "# x_test_small = x_test[idx_test]\n",
        "# y_test_small = y_test[idx_test]\n",
        "# print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "# print(collections.Counter(y_train_small))\n",
        "history = model.fit(x_train, y_train,batch_size=256, epochs=30, validation_data=(x_test, y_test), shuffle=True ,)\n",
        "#history = model.fit(x_train_small, y_train_small, batch_size=2048, epochs=30, validation_data=(x_test_small, y_test_small), shuffle=True ,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFPAkpw8zlPV"
      },
      "source": [
        "# Train and TE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoDjxVyaeoQJ"
      },
      "source": [
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc_score(test_ground_labels.astype(np.int32), max_distances))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}